{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import Linear, Embedding, RNN\n",
    "from torch.nn import Sigmoid, LogSoftmax\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss, NLLLoss\n",
    "from string import punctuation\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javascript</td>\n",
       "      <td>Angular.js expression: output transformed obje...</td>\n",
       "      <td>angularjs expression output transformed object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>android</td>\n",
       "      <td>How restart Fragment in my Activity - Android</td>\n",
       "      <td>how restart fragment in my activity  android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>javascript</td>\n",
       "      <td>node.js express, a very strange behaviour</td>\n",
       "      <td>nodejs express a very strange behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java</td>\n",
       "      <td>Open Editor Part in E4</td>\n",
       "      <td>open editor part in e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>javascript</td>\n",
       "      <td>Prevent Lazy Load of a Div in Laxy Load XT</td>\n",
       "      <td>prevent lazy load of a div in laxy load xt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text  \\\n",
       "0  javascript  Angular.js expression: output transformed obje...   \n",
       "1     android      How restart Fragment in my Activity - Android   \n",
       "2  javascript          node.js express, a very strange behaviour   \n",
       "3        java                             Open Editor Part in E4   \n",
       "4  javascript         Prevent Lazy Load of a Div in Laxy Load XT   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  angularjs expression output transformed object...  \n",
       "1       how restart fragment in my activity  android  \n",
       "2            nodejs express a very strange behaviour  \n",
       "3                             open editor part in e4  \n",
       "4         prevent lazy load of a div in laxy load xt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a DataFrame\n",
    "data = pd.read_pickle('../data/stackoverflow_gbq.pkl')\n",
    "\n",
    "# Definne a simple convenience function for cleaning the strings\n",
    "def clean_text(text):\n",
    "    return \"\".join([c for c in text.lower() if c not in punctuation])\n",
    "\n",
    "# Clean the string labels\n",
    "data['text_cleaned'] = data['text'].map(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = data['text_cleaned'].map(lambda x: x.split())\n",
    "all_words = set(list(itertools.chain.from_iterable(text_split)))\n",
    "vocab_size = len(all_words)\n",
    "word2idx = {word: idx for idx, word in enumerate(all_words)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(num_embeddings=vocab_size, embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4265, -0.8815,  0.8797, -0.5368,  0.9310, -0.8299, -0.1891,  0.1967,\n",
       "          0.0526, -2.3317,  0.5544, -0.1294,  0.4531, -0.1707, -0.7045, -0.2932,\n",
       "          0.8764,  0.0311,  0.0602,  0.5395,  1.7740, -1.8474,  1.7088, -0.4878,\n",
       "          0.4022,  0.4565, -0.1093, -1.0329,  1.2101,  0.0685,  0.5724, -0.6685,\n",
       "          0.1558,  1.3574, -0.6990,  0.6137, -0.2524, -0.2739, -1.5589, -1.0522,\n",
       "          0.3693, -1.0989,  0.9679,  0.6798,  1.0760, -1.4661,  0.8950, -0.1049,\n",
       "          0.3754, -0.9723,  0.0988, -0.1588,  0.3688,  0.7010, -0.6596,  0.6013,\n",
       "          0.0742,  0.0147,  0.1082, -0.6603,  0.5044, -0.8691, -0.3181, -1.6238,\n",
       "          0.4992, -1.9662, -0.5189, -0.2854, -0.9715,  1.0123, -0.6982, -0.1395,\n",
       "         -0.0131,  2.0896, -0.6927,  0.0927, -0.5720, -0.7166, -1.9849, -0.4276,\n",
       "          1.2579, -0.8066, -1.3512, -0.1447, -0.5385,  0.5194,  1.7851,  0.0293,\n",
       "          0.5075, -0.6541,  0.7000, -1.7866, -0.4941,  0.1871, -1.4818, -0.9636,\n",
       "          0.1738,  0.3717, -2.0590, -0.0978]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'python'\n",
    "idx = word2idx[word]\n",
    "embedding(torch.LongTensor([idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['idx_encoded'] = data['text_cleaned'].map(lambda x: [word2idx[word] for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 100])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.LongTensor(data.idx_encoded[0])).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=100, hidden_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = embedding(torch.LongTensor(data.idx_encoded[0])).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 100])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(e)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(data.label.values).reshape(-1,1)\n",
    "\n",
    "features = data['idx_encoded']\n",
    "\n",
    "train_data, test_data = train_test_split(list(zip(features, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_classifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(rnn_classifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = Embedding(num_embeddings=vocab_size, \n",
    "                                   embedding_dim=embedding_dim)\n",
    "        self.rnn = RNN(input_size=embedding_dim, \n",
    "                       hidden_size=hidden_dim)\n",
    "        self.linear = Linear(hidden_dim, output_dim)\n",
    "        self.softmax = LogSoftmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        e = self.embedding(x).unsqueeze(1)\n",
    "        out, hidden = self.rnn(e)\n",
    "        output = self.linear(hidden)\n",
    "        so = self.softmax(output.view(-1))\n",
    "        return so\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.rnn.weight_hh_l0 = torch.autograd.Variable(torch.zeros(self.hidden_dim, \n",
    "                                            self.hidden_dim))\n",
    "        self.rnn.weight_ih_l0 = torch.autograd.Variable(torch.zeros(self.hidden_dim, \n",
    "                                            2*self.hidden_dim))        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.FloatTensor' as parameter 'weight_hh_l0' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-61ba2b434584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-3e96c2372bcc>\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         self.rnn.weight_hh_l0 = torch.autograd.Variable(torch.zeros(self.hidden_dim, \n\u001b[0;32m---> 22\u001b[0;31m                                             self.hidden_dim))\n\u001b[0m\u001b[1;32m     23\u001b[0m         self.rnn.weight_ih_l0 = torch.autograd.Variable(torch.zeros(self.hidden_dim, \n\u001b[1;32m     24\u001b[0m                                             2*self.hidden_dim))        \n",
      "\u001b[0;32m/anaconda3/envs/deep-learning-nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    552\u001b[0m                 raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n\u001b[1;32m    553\u001b[0m                                 \u001b[0;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                                 .format(torch.typename(value), name))\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' as parameter 'weight_hh_l0' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "model = rnn_classifier(vocab_size = vocab_size, \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=50, \n",
    "                       output_dim=5)\n",
    "\n",
    "optim = SGD(params=model.parameters(), lr=0.01)\n",
    "criterion = NLLLoss()\n",
    "\n",
    "for f, t in train_data[:100]:\n",
    "    X = torch.LongTensor(f)\n",
    "    y = torch.LongTensor(t)\n",
    "    \n",
    "    model.init_hidden()\n",
    "    out = model.forward(X)\n",
    "    \n",
    "    loss = criterion(out.unsqueeze(0), y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deep-learning-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-1f53ebc9d9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "model = rnn_classifier(vocab_size = vocab_size, \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=50, \n",
    "                       output_dim=5)\n",
    "\n",
    "optim = SGD(params=model.parameters(), lr=0.01)\n",
    "criterion = NLLLoss()\n",
    "\n",
    "for f, t in train_data[:100]:\n",
    "    X = torch.LongTensor(f)\n",
    "    y = torch.LongTensor(t)\n",
    "    \n",
    "    e = embedding(X).unsqueeze(1)\n",
    "    \n",
    "    out, hidden = rnn(e)\n",
    "    \n",
    "    output = linear(hidden)\n",
    "    so = softmax(output.view(-1))\n",
    "    \n",
    "    loss = criterion(so.unsqueeze(0), y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0770, -0.0111, -0.0640,  0.1984, -0.0457], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 50])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
