{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.nn import Linear, Embedding, RNN, GRU, LSTM\n",
    "from torch.nn import Sigmoid, LogSoftmax\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import BCELoss, NLLLoss, CrossEntropyLoss\n",
    "from string import punctuation\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600702</th>\n",
       "      <td>Allow us to state that the opening of the inqu...</td>\n",
       "      <td>Permita que le digamos que las investigaciones...</td>\n",
       "      <td>[allow, us, to, state, that, the, opening, of,...</td>\n",
       "      <td>[permita, que, le, digamos, que, las, investig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>Since June of last year, the OLAF regulation h...</td>\n",
       "      <td>Desde junio del año pasado el Reglamento de la...</td>\n",
       "      <td>[since, june, of, last, year, the, olaf, regul...</td>\n",
       "      <td>[desde, junio, del, año, pasado, el, reglament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180999</th>\n",
       "      <td>I am fully aware of the views expressed here o...</td>\n",
       "      <td>Soy plenamente consciente de las opiniones exp...</td>\n",
       "      <td>[i, am, fully, aware, of, the, views, expresse...</td>\n",
       "      <td>[soy, plenamente, consciente, de, las, opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109251</th>\n",
       "      <td>I will have clarification of that situation la...</td>\n",
       "      <td>Hoy mismo recibiré información sobre dicha sit...</td>\n",
       "      <td>[i, will, have, clarification, of, that, situa...</td>\n",
       "      <td>[hoy, mismo, recibiré, información, sobre, dic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401751</th>\n",
       "      <td>Let us not forget, the Roma were the first to ...</td>\n",
       "      <td>No olvidemos que la población gitana fue la pr...</td>\n",
       "      <td>[let, us, not, forget, the, roma, were, the, f...</td>\n",
       "      <td>[no, olvidemos, que, la, población, gitana, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   english  \\\n",
       "600702   Allow us to state that the opening of the inqu...   \n",
       "3733     Since June of last year, the OLAF regulation h...   \n",
       "1180999  I am fully aware of the views expressed here o...   \n",
       "109251   I will have clarification of that situation la...   \n",
       "1401751  Let us not forget, the Roma were the first to ...   \n",
       "\n",
       "                                                   spanish  \\\n",
       "600702   Permita que le digamos que las investigaciones...   \n",
       "3733     Desde junio del año pasado el Reglamento de la...   \n",
       "1180999  Soy plenamente consciente de las opiniones exp...   \n",
       "109251   Hoy mismo recibiré información sobre dicha sit...   \n",
       "1401751  No olvidemos que la población gitana fue la pr...   \n",
       "\n",
       "                                                      text  \\\n",
       "600702   [allow, us, to, state, that, the, opening, of,...   \n",
       "3733     [since, june, of, last, year, the, olaf, regul...   \n",
       "1180999  [i, am, fully, aware, of, the, views, expresse...   \n",
       "109251   [i, will, have, clarification, of, that, situa...   \n",
       "1401751  [let, us, not, forget, the, roma, were, the, f...   \n",
       "\n",
       "                                                     label  \n",
       "600702   [permita, que, le, digamos, que, las, investig...  \n",
       "3733     [desde, junio, del, año, pasado, el, reglament...  \n",
       "1180999  [soy, plenamente, consciente, de, las, opinion...  \n",
       "109251   [hoy, mismo, recibiré, información, sobre, dic...  \n",
       "1401751  [no, olvidemos, que, la, población, gitana, fu...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../data/4_europarl_en_sp.pkl')\n",
    "data['text'] = data['english'].map(lambda x: \"\".join([i for i in x.lower() if i not in string.punctuation]).split())\n",
    "data['label'] = data['spanish'].map(lambda x: \"\".join([i for i in x.lower() if i not in string.punctuation]).split())\n",
    "#data = data[data.text.map(lambda x: 2 < len(x) <= 10 )]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600702</th>\n",
       "      <td>Allow us to state that the opening of the inqu...</td>\n",
       "      <td>Permita que le digamos que las investigaciones...</td>\n",
       "      <td>[&lt;SOS&gt;, allow, us, to, state, that, the, openi...</td>\n",
       "      <td>[&lt;EOS&gt;, coming, in, late, seemed, inquiry, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>Since June of last year, the OLAF regulation h...</td>\n",
       "      <td>Desde junio del año pasado el Reglamento de la...</td>\n",
       "      <td>[&lt;SOS&gt;, since, june, of, last, year, the, olaf...</td>\n",
       "      <td>[&lt;EOS&gt;, irregularities, possible, reporting, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180999</th>\n",
       "      <td>I am fully aware of the views expressed here o...</td>\n",
       "      <td>Soy plenamente consciente de las opiniones exp...</td>\n",
       "      <td>[&lt;SOS&gt;, i, am, fully, aware, of, the, views, e...</td>\n",
       "      <td>[&lt;EOS&gt;, manner, adequate, an, in, process, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109251</th>\n",
       "      <td>I will have clarification of that situation la...</td>\n",
       "      <td>Hoy mismo recibiré información sobre dicha sit...</td>\n",
       "      <td>[&lt;SOS&gt;, i, will, have, clarification, of, that...</td>\n",
       "      <td>[&lt;EOS&gt;, day, the, in, later, situation, that, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401751</th>\n",
       "      <td>Let us not forget, the Roma were the first to ...</td>\n",
       "      <td>No olvidemos que la población gitana fue la pr...</td>\n",
       "      <td>[&lt;SOS&gt;, let, us, not, forget, the, roma, were,...</td>\n",
       "      <td>[&lt;EOS&gt;, area, common, our, up, set, had, we, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   english  \\\n",
       "600702   Allow us to state that the opening of the inqu...   \n",
       "3733     Since June of last year, the OLAF regulation h...   \n",
       "1180999  I am fully aware of the views expressed here o...   \n",
       "109251   I will have clarification of that situation la...   \n",
       "1401751  Let us not forget, the Roma were the first to ...   \n",
       "\n",
       "                                                   spanish  \\\n",
       "600702   Permita que le digamos que las investigaciones...   \n",
       "3733     Desde junio del año pasado el Reglamento de la...   \n",
       "1180999  Soy plenamente consciente de las opiniones exp...   \n",
       "109251   Hoy mismo recibiré información sobre dicha sit...   \n",
       "1401751  No olvidemos que la población gitana fue la pr...   \n",
       "\n",
       "                                                      text  \\\n",
       "600702   [<SOS>, allow, us, to, state, that, the, openi...   \n",
       "3733     [<SOS>, since, june, of, last, year, the, olaf...   \n",
       "1180999  [<SOS>, i, am, fully, aware, of, the, views, e...   \n",
       "109251   [<SOS>, i, will, have, clarification, of, that...   \n",
       "1401751  [<SOS>, let, us, not, forget, the, roma, were,...   \n",
       "\n",
       "                                                     label  \n",
       "600702   [<EOS>, coming, in, late, seemed, inquiry, the...  \n",
       "3733     [<EOS>, irregularities, possible, reporting, a...  \n",
       "1180999  [<EOS>, manner, adequate, an, in, process, thi...  \n",
       "109251   [<EOS>, day, the, in, later, situation, that, ...  \n",
       "1401751  [<EOS>, area, common, our, up, set, had, we, b...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].map(lambda x: ['<SOS>'] + x + ['<EOS>'])\n",
    "data['label'] = data['label'].map(lambda x: ['<SOS>'] + x + ['<EOS>'])\n",
    "\n",
    "\n",
    "data = data[data.label.map(lambda x: len(x)!=2)]\n",
    "data = data[data.text.map(lambda x: len(x)!=2)]\n",
    "\n",
    "data['label'] = data['text'].map(lambda x: list(reversed(x)))\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = set(itertools.chain.from_iterable(data['text']))\n",
    "output_words = set(itertools.chain.from_iterable(data['label']))\n",
    "\n",
    "input2idx = {word: idx for idx, word in enumerate(input_words)}\n",
    "idx2input = {idx: word for word, idx in input2idx.items()}\n",
    "\n",
    "output2idx = {word: idx for idx, word in enumerate(output_words)}\n",
    "idx2output = {idx: word for word, idx in output2idx.items()}\n",
    "\n",
    "input_size = len(input_words)\n",
    "output_size = len(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, batch_size):\n",
    "        super(decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = Embedding(num_embeddings=vocab_size, \n",
    "                                   embedding_dim=embedding_dim)\n",
    "        self.rnn = LSTM(input_size=embedding_dim, \n",
    "                       hidden_size=hidden_dim)\n",
    "        self.linear = Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = batch_size\n",
    "        self.softmax = LogSoftmax(dim=1)\n",
    "                \n",
    "    def forward(self, input, hidden):\n",
    "        e = self.embedding(input)\n",
    "        e = e.unsqueeze(1)\n",
    "        out, hidden = self.rnn(e, hidden)\n",
    "        output = self.linear(out).squeeze(1)\n",
    "        so = self.softmax(output)\n",
    "        return so, hidden\n",
    "                  \n",
    "    def init_hidden(self):\n",
    "        h0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        c0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_indices = {\n",
    "                        'input2idx': input2idx, \n",
    "                        'idx2input': idx2input, \n",
    "                        'output2idx': output2idx, \n",
    "                        'idx2putput': idx2output\n",
    "                      }\n",
    "\n",
    "with open('../data/translation_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(translation_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = data['text'].map(lambda x: [input2idx[i] for i in x]).tolist()\n",
    "output_seqs = data['label'].map(lambda x: [output2idx[i] for i in x]).tolist()\n",
    "\n",
    "all_data = list(zip(input_seqs, output_seqs))\n",
    "\n",
    "train_data, test_data = train_test_split(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vocab_size = input_size\n",
    "dec_embedding_dim = 100\n",
    "dec_hidden_dim = 100\n",
    "dec_output_dim = input_size\n",
    "\n",
    "\n",
    "dec = decoder(dec_vocab_size, dec_embedding_dim, dec_hidden_dim, dec_output_dim, batch_size=1)\n",
    "optim = Adam(params=dec.parameters(), lr=0.01)\n",
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch|it: 0|500, Total Loss: 6.77\n",
      "['a', 'second', 'appeal', 'a', 'number', 'of', 'national', 'governments', 'many', 'political', 'parties', 'and', 'members', 'of', 'parliament', 'are', 'in', 'principle', 'opposed', 'to', 'the', 'use', 'of', 'animal', 'fats', '<EOS>']\n",
      "['the', 'the', '<EOS>', '<EOS>', 'the', '<EOS>', 'the', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', 'the', '<EOS>', 'the', '<EOS>', '<EOS>', 'the', '<EOS>', '<EOS>', 'the', 'situation', '<EOS>', 'the', 'the', '<EOS>']\n",
      "Epoch|it: 0|1000, Total Loss: 6.59\n",
      "['i', 'do', 'not', 'feel', 'that', 'this', 'alternative', 'should', 'be', 'accepted', '<EOS>']\n",
      "['i', 'believe', 'not', 'the', '<EOS>', 'the', 'is', 'the', 'be', 'the', '<EOS>']\n",
      "Epoch|it: 0|1500, Total Loss: 6.47\n",
      "['with', 'the', 'stability', 'and', 'growth', 'pact', 'in', 'mind', 'i', 'demand', 'that', 'you', 'insist', 'on', 'compliance', 'with', 'the', 'law', '<EOS>']\n",
      "['the', 'the', 'european', 'of', '<EOS>', '<EOS>', '<EOS>', 'the', '<EOS>', 'am', '<EOS>', 'the', 'the', '<EOS>', 'the', '<EOS>', 'the', 'european', 'of']\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for it, example in enumerate(train_data):\n",
    "        if (it % 500 == 0) and (it != 0):\n",
    "            print(\"Epoch|it: {}|{}, Total Loss: {:.2f}\".format(epoch, it, total_loss / it))\n",
    "            print([idx2output[i] for i in trues])\n",
    "            print([idx2output[i] for i in preds])\n",
    "        input_seq, output_seq = example\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        \n",
    "        hidden = dec.init_hidden()\n",
    "        \n",
    "        res, hidden = dec.forward(input_seq[:-1], hidden)\n",
    "        loss = criterion(res.squeeze(1), input_seq[1:])\n",
    "        loss.backward()\n",
    "        total_loss += loss.data.numpy()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(input_seq[1:].data.numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input_seq\n",
    "e = dec.embedding(input)\n",
    "e = e.unsqueeze(1)\n",
    "out, hidden = dec.rnn(e, hidden)\n",
    "output = dec.linear(out).squeeze(1)\n",
    "so = dec.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.9707, -8.1693, -8.2923,  ..., -8.3863, -8.1633, -8.0869],\n",
       "        [-8.0139, -8.1526, -8.3940,  ..., -8.4141, -8.2088, -8.3393],\n",
       "        [-8.0989, -8.2096, -8.4639,  ..., -8.2992, -8.1661, -8.2258],\n",
       "        ...,\n",
       "        [-8.0084, -8.1881, -8.3445,  ..., -8.2062, -8.3656, -8.2368],\n",
       "        [-8.1319, -8.3160, -8.4182,  ..., -8.3137, -8.1838, -8.2401],\n",
       "        [-8.1732, -8.3812, -8.3558,  ..., -8.3213, -8.1724, -8.3135]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 3535])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = dec.embedding(input_seq)\n",
    "o, h = dec.rnn(e.unsqueeze(1), hidden)\n",
    "l = dec.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(dec.softmax(l.squeeze(1))).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size):\n",
    "        super(encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = Embedding(num_embeddings=vocab_size, \n",
    "                                   embedding_dim=embedding_dim)\n",
    "        self.rnn = LSTM(input_size=embedding_dim, \n",
    "                       hidden_size=hidden_dim)\n",
    "        self.batch_size = batch_size\n",
    "        self.softmax = LogSoftmax()\n",
    "        self.hidden = self.init_hidden()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        e = self.embedding(x)\n",
    "        e = e.view(len(x), self.batch_size, -1)\n",
    "        out, self.hidden = self.rnn(e, self.hidden)\n",
    "        return out, self.hidden\n",
    "                  \n",
    "    def init_hidden(self):\n",
    "        h0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        c0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "    \n",
    "class decoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, batch_size):\n",
    "        super(decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = Embedding(num_embeddings=vocab_size, \n",
    "                                   embedding_dim=embedding_dim)\n",
    "        self.rnn = LSTM(input_size=embedding_dim, \n",
    "                       hidden_size=hidden_dim)\n",
    "        self.linear = Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = batch_size\n",
    "        self.softmax = LogSoftmax(dim=1)\n",
    "        self.hidden = self.init_hidden()\n",
    "                \n",
    "    def forward(self, input, hidden):\n",
    "        self.hidden = hidden\n",
    "        e = self.embedding(input)\n",
    "        e = e.view(len(input), self.batch_size, -1)\n",
    "        out, self.hidden = self.rnn(e, self.hidden)\n",
    "        self.out = out\n",
    "        output = self.linear(out[0])\n",
    "        so = self.softmax(output)\n",
    "        return so, self.hidden\n",
    "                  \n",
    "    def init_hidden(self):\n",
    "        h0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        c0 = torch.autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "    \n",
    "class seq2seq(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.enc = encoder\n",
    "        self.dec = decoder\n",
    "                \n",
    "    def forward(self, input_seq, output_seq, p_tf=0):\n",
    "        outputs = []\n",
    "        \n",
    "        self.enc.hidden = self.enc.init_hidden()\n",
    "        self.dec.hidden = self.dec.init_hidden()        \n",
    "        \n",
    "        enc_output, enc_hidden = enc.forward(torch.LongTensor(input_seq))\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        for i in range(output_seq.shape[0]):\n",
    "            dec_input = torch.LongTensor([output_seq[i]])\n",
    "            dec_output, dec_hidden = self.dec.forward(dec_input, dec_hidden) \n",
    "            outputs.append(dec_output)\n",
    "        return torch.stack(outputs).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab_size = input_size\n",
    "enc_embedding_dim = 100\n",
    "enc_hidden_dim = 100\n",
    "\n",
    "dec_vocab_size = output_size\n",
    "dec_embedding_dim = 100\n",
    "dec_hidden_dim = 100\n",
    "dec_output_dim = output_size\n",
    "\n",
    "enc = encoder(enc_vocab_size, enc_embedding_dim, enc_hidden_dim, batch_size=1)\n",
    "dec = decoder(dec_vocab_size, dec_embedding_dim, dec_hidden_dim, dec_output_dim, batch_size=1)\n",
    "s2s = seq2seq(enc, dec)\n",
    "\n",
    "\n",
    "optim = SGD(params=s2s.parameters(), lr=0.01)\n",
    "criterion = NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    s2s.train()\n",
    "    total_loss = 0\n",
    "    s2s.train()\n",
    "    for it, example in enumerate(train_data):\n",
    "        if (it % 500 == 0) and (it != 0):\n",
    "            print(\"Epoch|it: {}|{}, Total Loss: {:.2f}\".format(epoch, it, total_loss / it))\n",
    "            print(loss.data.numpy())\n",
    "            print(preds)\n",
    "        input_seq, output_seq = example\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        output_seq = torch.LongTensor(output_seq)\n",
    "          \n",
    "        res = s2s.forward(input_seq, output_seq[:-1])\n",
    "        loss = criterion(res, output_seq[1:])\n",
    "        loss.backward()\n",
    "        total_loss += loss.data.numpy()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        \n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(output_seq[1:].data.numpy())\n",
    "        y_train_true.extend(trues)\n",
    "        y_train_pred.extend(preds)\n",
    "    \n",
    "    y_test_pred = []\n",
    "    y_test_true = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2putput[6994]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[4.3980e-05, 4.3541e-05, 4.5462e-05, 5.0658e-05, 4.7762e-05, 5.2381e-05,\n",
    "        5.5144e-05, 5.4351e-05, 4.9266e-05, 5.4104e-05, 5.1706e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.LongTensor(input_seqs[3])\n",
    "c, h = s2s.enc.forward(input_seq)\n",
    "\n",
    "output, hidden = s2s.dec.forward(torch.LongTensor([15310]), h)\n",
    "\n",
    "pred = torch.argmax(output)\n",
    "for i in range(30):\n",
    "    pred = torch.argmax(output)\n",
    "    output, hidden = s2s.dec.forward(torch.LongTensor([pred]), hidden)\n",
    "    print(idx2putput[int(pred.numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    s2s.train()\n",
    "    total_loss = 0\n",
    "    s2s.train()\n",
    "    y_test_pred = []\n",
    "    y_test_true = []\n",
    "    y_train_pred = []\n",
    "    y_train_true = []\n",
    "    for it, example in enumerate(train_data):\n",
    "        if (it % 500 == 0) and (it != 0):\n",
    "            print(\"Epoch|it: {}|{}, Total Loss: {:.2f}\".format(epoch, it, total_loss / it))\n",
    "        input_seq, output_seq = example\n",
    "        enc_optim.zero_grad()\n",
    "        dec_optim.zero_grad()\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        output_seq = torch.LongTensor(output_seq)    \n",
    "        res = s2s.forward(input_seq, output_seq)\n",
    "        loss = criterion(res, torch.LongTensor(output_seq))\n",
    "        loss.backward()\n",
    "        total_loss += loss.data.numpy()\n",
    "\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "        \n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(output_seq.data.numpy())\n",
    "        y_train_true.extend(trues)\n",
    "        y_train_pred.extend(preds)\n",
    "        \n",
    "    a_train = accuracy_score(y_train_true, y_train_pred)\n",
    "    \n",
    "    s2s.eval()\n",
    "    y_test_pred = []\n",
    "    y_test_true = []\n",
    "    \"\"\"\n",
    "    for example in test_data:\n",
    "\n",
    "        input_seq, output_seq = example\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        output_seq = torch.LongTensor(output_seq)    \n",
    "        res = s2s.forward(input_seq, output_seq)\n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(output_seq.data.numpy())\n",
    "\n",
    "        y_test_true.extend(trues)\n",
    "        y_test_pred.extend(preds)\n",
    "\n",
    "    a_test = accuracy_score(y_test_true, y_test_pred)\n",
    "    \n",
    "    print(\"Epoch {} Loss: {:.2f}, Train/Test Accuracy: {:.3}/{:.3f}\".format(epoch, total_loss / it, a_train, a_test))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(input_seq.numpy()):\n",
    "    print(idx2input[i])\n",
    "\n",
    "for i in list(output_seq.numpy()):\n",
    "    print(idx2putput[i])    \n",
    "    \n",
    "break_level = 10\n",
    "\n",
    "model = s2s\n",
    "\n",
    "preds = []\n",
    "\n",
    "model.enc.hidden = model.enc.init_hidden()\n",
    "model.dec.hidden = model.dec.init_hidden()        \n",
    "\n",
    "enc_output, enc_hidden = model.enc(input_seq)\n",
    "context = (enc_output[-1].unsqueeze(1), enc_output[-1].unsqueeze(1))\n",
    "\n",
    "dec_sos = torch.LongTensor([sos_int])\n",
    "\n",
    "dec_output, hidden = model.dec.forward(dec_sos, context)\n",
    "pred = torch.argmax(dec_output[-1])\n",
    "preds.append(int(pred.data.numpy()))\n",
    "\n",
    "it = 0\n",
    "\n",
    "while pred != eos_int:\n",
    "    it += 1\n",
    "    if it > break_level:\n",
    "        break\n",
    "    dec_output, hidden = model.dec.forward(torch.LongTensor([pred]), hidden)\n",
    "    pred = torch.argmax(dec_output[-1])\n",
    "    preds.append(int(pred.data.numpy()))\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = model.dec.forward(torch.LongTensor([15310]), hidden)\n",
    "torch.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.LongTensor(test_data[0][0])\n",
    "sos_int = output2idx['<SOS>']\n",
    "eos_int = output2idx['<EOS>']\n",
    "preds = predict(s2s, sample, sos_int, eos_int)\n",
    "for p in preds:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "s2s.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    s2s.train()\n",
    "    y_test_pred = []\n",
    "    y_test_true = []\n",
    "    y_train_pred = []\n",
    "    y_train_true = []\n",
    "    for it, example in enumerate(train_data):\n",
    "        if (it % 500 == 0) and (it != 0):\n",
    "            print(\"Epoch|it: {}|{}, Total Loss: {:.2f}\".format(epoch, it, total_loss / it))\n",
    "        input_seq, output_seq = example\n",
    "        enc_optim.zero_grad()\n",
    "        dec_optim.zero_grad()\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        output_seq = torch.LongTensor(output_seq)    \n",
    "        res = s2s.forward(input_seq, output_seq)\n",
    "        loss = criterion(res, torch.LongTensor(output_seq))\n",
    "        loss.backward()\n",
    "        total_loss += loss.data.numpy()\n",
    "\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "        \n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(output_seq.data.numpy())\n",
    "        y_train_true.extend(trues)\n",
    "        y_train_pred.extend(preds)\n",
    "        \n",
    "    a_train = accuracy_score(y_train_true, y_train_pred)\n",
    "    \n",
    "    s2s.eval()\n",
    "    y_test_pred = []\n",
    "    y_test_true = []\n",
    "\n",
    "    for example in test_data:\n",
    "\n",
    "        input_seq, output_seq = example\n",
    "\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        output_seq = torch.LongTensor(output_seq)    \n",
    "        res = s2s.forward(input_seq, output_seq)\n",
    "        preds = list(torch.argmax(res, dim=1).data.numpy())\n",
    "        trues = list(output_seq.data.numpy())\n",
    "\n",
    "        y_test_true.extend(trues)\n",
    "        y_test_pred.extend(preds)\n",
    "\n",
    "    a_test = accuracy_score(y_test_true, y_test_pred)\n",
    "    \n",
    "    print(\"Epoch {} Loss: {:.2f}, Train/Test Accuracy: {:.3}/{:.3f}\".format(epoch, total_loss / it, a_train, a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.seq2seq import encoder, decoder, seq2seq\n",
    "torch.save(s2s, '../data/seq2seq.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
